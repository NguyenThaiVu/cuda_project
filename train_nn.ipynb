{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:  tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "  except RuntimeError as e:  print(e)\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (60000, 784)\n",
      "Shape of y_train: (60000, 10)\n",
      "Shape of X_test: (10000, 784)\n",
      "Shape of y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Flatten the 28x28 images into vectors of 784 elements\n",
    "x_train = x_train.reshape(-1, 28 * 28).astype('float32') / 255\n",
    "x_test = x_test.reshape(-1, 28 * 28).astype('float32') / 255\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "        \n",
    "print(f\"Shape of X_train: {x_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of X_test: {x_test.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(0, x_train.shape[0])\n",
    "image = x_train[idx].reshape(28, 28)\n",
    "label = y_train[idx]\n",
    "\n",
    "plt.imshow(image, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_in, n_out, activation=None):\n",
    "        super(CustomDense, self).__init__()\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Initialize weights and bias\n",
    "        self.w = self.add_weight(shape=(self.n_in, self.n_out), initializer='random_normal', trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.n_out,), initializer='random_normal', trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z = tf.matmul(inputs, self.w) + self.b  \n",
    "        if self.activation:\n",
    "            z = self.activation(z)  \n",
    "        return z  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "input_size = 784\n",
    "hidden_layer_size = 128\n",
    "output_size = 10\n",
    "\n",
    "# Building the Fully Connected Neural Network\n",
    "tf.keras.backend.clear_session()\n",
    "model = Sequential([\n",
    "    CustomDense(n_in=input_size, n_out=hidden_layer_size),  \n",
    "    layers.Activation('relu'),\n",
    "    CustomDense(n_in=hidden_layer_size, n_out=output_size),\n",
    "    layers.Activation('softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 729us/step - loss: 0.2906 - accuracy: 0.9187 - val_loss: 0.1469 - val_accuracy: 0.9573\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 683us/step - loss: 0.1248 - accuracy: 0.9629 - val_loss: 0.1043 - val_accuracy: 0.9682\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 675us/step - loss: 0.0843 - accuracy: 0.9752 - val_loss: 0.0862 - val_accuracy: 0.9739\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 682us/step - loss: 0.0612 - accuracy: 0.9815 - val_loss: 0.0770 - val_accuracy: 0.9762\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 684us/step - loss: 0.0484 - accuracy: 0.9852 - val_loss: 0.0758 - val_accuracy: 0.9762\n",
      "313/313 - 0s - loss: 0.0758 - accuracy: 0.9762 - 164ms/epoch - 522us/step\n",
      "Test accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save trained weight into `txt` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_WEIGHT_FOLDER = r\"weight\"\n",
    "\n",
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and biases saved to separate .txt files.\n"
     ]
    }
   ],
   "source": [
    "# Save layer 1 (weights and biases)\n",
    "np.savetxt(os.path.join(PATH_WEIGHT_FOLDER, 'hidden_weights.txt'), weights[0].flatten(), fmt='%f', delimiter=' ')\n",
    "np.savetxt(os.path.join(PATH_WEIGHT_FOLDER, 'hidden_bias.txt'), weights[1], fmt='%f', delimiter=' ')\n",
    "\n",
    "# Save layer 2 (weights and biases)\n",
    "np.savetxt(os.path.join(PATH_WEIGHT_FOLDER, 'output_weights.txt'), weights[2].flatten(), fmt='%f', delimiter=' ')\n",
    "np.savetxt(os.path.join(PATH_WEIGHT_FOLDER, 'output_bias.txt'), weights[3], fmt='%f', delimiter=' ')\n",
    "\n",
    "print(\"Weights and biases saved to separate .txt files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = 'image/digit_gray.jpg'\n",
    "\n",
    "img = image.load_img(input_image_path, target_size=(28, 28), color_mode=\"grayscale\")\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = img_array / 255.0  \n",
    "img_array = np.reshape(img_array, (1, 784))  # Flatten the image to shape (1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "Model Inference (Softmax Probabilities): [4.1252638e-13 9.5248961e-16 9.9651015e-07 1.6341355e-06 6.5210619e-23\n",
      " 1.3017629e-03 2.1087857e-15 9.9869567e-01 5.7997686e-18 1.0085674e-19]\n",
      "Predicted Digit: 7\n",
      "Predicted Digit Probability: 0.9987\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(img_array)[0]\n",
    "\n",
    "print(\"Model Inference (Softmax Probabilities):\", prediction)\n",
    "print(\"Predicted Digit:\", np.argmax(prediction))\n",
    "print(f\"Predicted Digit Probability: {prediction[np.argmax(prediction)]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert image to grayscale for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = 'image/digit.jpg'  \n",
    "image = Image.open(input_image_path)\n",
    "\n",
    "gray_image = image.convert('L')\n",
    "\n",
    "resized_image = gray_image.resize((28, 28))\n",
    "\n",
    "# Save the resulting image\n",
    "output_image_path = 'image/digit_gray.jpg'\n",
    "resized_image.save(output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
